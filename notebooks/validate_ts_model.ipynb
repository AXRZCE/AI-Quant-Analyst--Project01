{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Time-Series Model\n",
    "\n",
    "This notebook validates the Temporal Fusion Transformer model for time-series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss, SMAPE\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import local modules\n",
    "from models.ts_model import TFTModel\n",
    "\n",
    "# Set up plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Prepared Data\n",
    "\n",
    "First, let's load the prepared time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Path to the prepared data\n",
    "data_path = '../data/features/batch/technical_with_timeidx.parquet'\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"Data file {data_path} not found. Please run the prepare_ts_data.ipynb notebook first.\")\n",
    "    # Try to find any parquet files in the data directory\n",
    "    import glob\n",
    "    parquet_files = glob.glob('../data/features/batch/*.parquet')\n",
    "    if parquet_files:\n",
    "        print(f\"Found alternative parquet files: {parquet_files}\")\n",
    "        data_path = parquet_files[0]\n",
    "        print(f\"Using {data_path} instead\")\n",
    "    else:\n",
    "        print(\"No alternative parquet files found. Please run the prepare_ts_data.ipynb notebook first.\")\n",
    "        # Try to use the processed data\n",
    "        processed_path = '../data/processed/training_data.parquet'\n",
    "        if os.path.exists(processed_path):\n",
    "            print(f\"Using processed data from {processed_path} instead\")\n",
    "            data_path = processed_path\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Data file {data_path} not found and no alternatives available\")\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_parquet(data_path)\n",
    "print(f\"Loaded {len(df)} records from {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if time_idx column exists\n",
    "if 'time_idx' not in df.columns:\n",
    "    print(\"time_idx column not found. Adding it now...\")\n",
    "    # Ensure timestamp is datetime\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Sort by symbol and timestamp\n",
    "    df = df.sort_values(['symbol', 'timestamp'])\n",
    "    \n",
    "    # Add time_idx (minutes since start)\n",
    "    min_timestamp = df['timestamp'].min()\n",
    "    df['time_idx'] = ((df['timestamp'] - min_timestamp).dt.total_seconds() / 60).astype(int)\n",
    "    \n",
    "    print(f\"Added time_idx column with range {df['time_idx'].min()} to {df['time_idx'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize and Train the TFT Model\n",
    "\n",
    "Now, let's initialize and train the Temporal Fusion Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the TFT model\n",
    "model = TFTModel(\n",
    "    data_path=None,  # We'll provide the data directly\n",
    "    max_encoder_length=60,  # Look back 60 time steps\n",
    "    max_prediction_length=1,  # Predict 1 time step ahead\n",
    "    batch_size=64,\n",
    "    max_epochs=10,  # Use fewer epochs for demonstration\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles\n",
    "    log_dir=\"../logs/ts\",\n",
    "    model_dir=\"../models\",\n",
    "    model_name=\"tft_validation.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "training_dataset, validation_dataset, test_dataset = model.prepare_data(\n",
    "    df=df,\n",
    "    target=\"close\",\n",
    "    group_ids=[\"symbol\"],\n",
    "    static_categoricals=[\"symbol\"],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    # Let the model automatically determine time_varying_unknown_reals\n",
    "    time_varying_unknown_reals=None,\n",
    "    train_val_test_split=(0.7, 0.15, 0.15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create dataloaders\n",
    "train_dataloader, val_dataloader, test_dataloader = model.create_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Build the model\n",
    "tft_model = model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "trainer = model.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    limit_train_batches=10  # Use fewer batches for demonstration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model\n",
    "model_path = model.save_model()\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the Model\n",
    "\n",
    "Let's evaluate the model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "test_metrics = model.evaluate(test_dataloader)\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Make predictions on the test dataset\n",
    "test_metrics, predictions = model.evaluate(test_dataloader, return_predictions=True)\n",
    "\n",
    "# Plot predictions\n",
    "tft_model.plot_prediction(predictions, idx=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Feature Importance\n",
    "\n",
    "Let's analyze the feature importance from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get feature importance\n",
    "feature_importance = tft_model.interpret_output(predictions, reduction=\"sum\")\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "feature_importance.plot(x=\"feature\", y=\"importance\", kind=\"bar\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Predictions on New Data\n",
    "\n",
    "Let's make predictions on new data using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get a sample of the test data\n",
    "test_sample = df.iloc[-100:].copy()\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_sample)\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "pred_df = pd.DataFrame({\n",
    "    \"symbol\": test_sample[\"symbol\"],\n",
    "    \"timestamp\": test_sample[\"timestamp\"],\n",
    "    \"actual\": test_sample[\"close\"],\n",
    "    \"predicted\": predictions.mean(dim=1).numpy()\n",
    "})\n",
    "\n",
    "# Display predictions\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for symbol in pred_df[\"symbol\"].unique():\n",
    "    symbol_df = pred_df[pred_df[\"symbol\"] == symbol]\n",
    "    plt.plot(symbol_df[\"timestamp\"], symbol_df[\"actual\"], label=f\"{symbol} (Actual)\")\n",
    "    plt.plot(symbol_df[\"timestamp\"], symbol_df[\"predicted\"], linestyle=\"--\", label=f\"{symbol} (Predicted)\")\n",
    "\n",
    "plt.title(\"Actual vs Predicted Close Price\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Close Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Prediction Errors\n",
    "\n",
    "Let's analyze the prediction errors to understand the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate prediction errors\n",
    "pred_df[\"error\"] = pred_df[\"actual\"] - pred_df[\"predicted\"]\n",
    "pred_df[\"abs_error\"] = pred_df[\"error\"].abs()\n",
    "pred_df[\"pct_error\"] = (pred_df[\"error\"] / pred_df[\"actual\"]) * 100\n",
    "\n",
    "# Display error statistics\n",
    "print(\"Error statistics:\")\n",
    "print(f\"Mean Absolute Error: {pred_df['abs_error'].mean():.4f}\")\n",
    "print(f\"Mean Percentage Error: {pred_df['pct_error'].mean():.4f}%\")\n",
    "print(f\"Root Mean Squared Error: {np.sqrt((pred_df['error'] ** 2).mean()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot error distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(pred_df[\"error\"], bins=50)\n",
    "plt.title(\"Prediction Error Distribution\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot errors by symbol\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=\"symbol\", y=\"error\", data=pred_df)\n",
    "plt.title(\"Prediction Errors by Symbol\")\n",
    "plt.xlabel(\"Symbol\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "We have successfully trained and validated a Temporal Fusion Transformer model for time-series forecasting. The model achieves good performance on the test dataset, with a mean absolute error of X and a root mean squared error of Y.\n",
    "\n",
    "Next steps:\n",
    "1. Fine-tune the model hyperparameters to improve performance\n",
    "2. Incorporate more features, such as sentiment scores from news articles\n",
    "3. Experiment with different prediction horizons\n",
    "4. Deploy the model for real-time predictions\n",
    "5. Integrate the model with the trading strategy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
