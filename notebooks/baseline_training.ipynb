{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model Training\n",
    "\n",
    "This notebook trains a baseline XGBoost model for predicting stock returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import local modules\n",
    "from models.data_loader import load_training_data, prepare_features, get_feature_label_split, train_test_split\n",
    "from models.train_baseline import train_xgboost_model, evaluate_model, save_model\n",
    "\n",
    "# Set up plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "First, let's load the data and prepare it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define parameters\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL']\n",
    "start_date = '2025-04-01'\n",
    "end_date = '2025-04-17'\n",
    "label_horizon = 1  # Predict next period's return\n",
    "label_type = 'return'  # 'return' or 'direction'\n",
    "\n",
    "# Load data\n",
    "df = load_training_data(\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    symbols=symbols,\n",
    "    use_feast=False,  # Set to True if using Feast\n",
    "    label_horizon=label_horizon,\n",
    "    label_type=label_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display data summary\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Symbols: {df['symbol'].unique().tolist()}\")\n",
    "\n",
    "if 'timestamp' in df.columns:\n",
    "    print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values:\")\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check label distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['label'].dropna(), bins=50)\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print label statistics\n",
    "print(\"Label statistics:\")\n",
    "print(df['label'].describe())\n",
    "\n",
    "# Print percentage of positive returns\n",
    "positive_returns = (df['label'] > 0).mean() * 100\n",
    "print(f\"Percentage of positive returns: {positive_returns:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split Data into Train, Validation, and Test Sets\n",
    "\n",
    "We'll use a time-based split to avoid look-ahead bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split data\n",
    "data_splits = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    validation_size=0.1,\n",
    "    shuffle=False  # Time-based split\n",
    ")\n",
    "\n",
    "train_df = data_splits['train']\n",
    "val_df = data_splits['validation']\n",
    "test_df = data_splits['test']\n",
    "\n",
    "print(f\"Train set: {len(train_df)} records\")\n",
    "print(f\"Validation set: {len(val_df)} records\")\n",
    "print(f\"Test set: {len(test_df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare features and labels\n",
    "train_data = get_feature_label_split(train_df, label_column=\"label\")\n",
    "val_data = get_feature_label_split(val_df, label_column=\"label\")\n",
    "test_data = get_feature_label_split(test_df, label_column=\"label\")\n",
    "\n",
    "X_train, y_train = train_data[\"X\"], train_data[\"y\"]\n",
    "X_val, y_val = val_data[\"X\"], val_data[\"y\"]\n",
    "X_test, y_test = test_data[\"X\"], test_data[\"y\"]\n",
    "\n",
    "print(f\"Features: {X_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Analysis\n",
    "\n",
    "Let's analyze the features to understand their distributions and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature correlation with label\n",
    "feature_corr = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'correlation': [X_train[col].corr(y_train) for col in X_train.columns]\n",
    "}).sort_values('correlation', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='correlation', y='feature', data=feature_corr)\n",
    "plt.title('Feature Correlation with Label')\n",
    "plt.xlabel('Correlation')\n",
    "plt.ylabel('Feature')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature correlation matrix\n",
    "plt.figure(figsize=(14, 12))\n",
    "corr_matrix = X_train.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train XGBoost Model\n",
    "\n",
    "Now, let's train an XGBoost model to predict stock returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up XGBoost parameters\n",
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# Train model\n",
    "model, train_metrics = train_xgboost_model(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    params=params,\n",
    "    use_wandb=False  # Set to True to log to Weights & Biases\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model on Test Set\n",
    "\n",
    "Let's evaluate the model on the test set to see how well it generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = evaluate_model(model, X_test, y_test, use_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot actual vs predicted\n",
    "preds = model.predict(X_test)\n",
    "results_df = pd.DataFrame({\n",
    "    \"Actual\": y_test,\n",
    "    \"Predicted\": preds\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(results_df[\"Actual\"], results_df[\"Predicted\"], alpha=0.5)\n",
    "plt.plot([-0.1, 0.1], [-0.1, 0.1], 'r--')\n",
    "plt.title(\"Actual vs Predicted Returns\")\n",
    "plt.xlabel(\"Actual Return\")\n",
    "plt.ylabel(\"Predicted Return\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze prediction errors\n",
    "results_df[\"Error\"] = results_df[\"Actual\"] - results_df[\"Predicted\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(results_df[\"Error\"], bins=50)\n",
    "plt.title(\"Prediction Error Distribution\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print error statistics\n",
    "print(\"Error statistics:\")\n",
    "print(results_df[\"Error\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze directional accuracy\n",
    "results_df[\"Actual_Direction\"] = (results_df[\"Actual\"] > 0).astype(int)\n",
    "results_df[\"Predicted_Direction\"] = (results_df[\"Predicted\"] > 0).astype(int)\n",
    "results_df[\"Direction_Match\"] = (results_df[\"Actual_Direction\"] == results_df[\"Predicted_Direction\"]).astype(int)\n",
    "\n",
    "directional_accuracy = results_df[\"Direction_Match\"].mean() * 100\n",
    "print(f\"Directional Accuracy: {directional_accuracy:.2f}%\")\n",
    "\n",
    "# Confusion matrix for directional prediction\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(results_df[\"Actual_Direction\"], results_df[\"Predicted_Direction\"])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Down\", \"Up\"])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Directional Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model\n",
    "\n",
    "Let's save the trained model for later use in backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "output_path = \"../models/baseline_xgb.pkl\"\n",
    "\n",
    "# Combine metrics\n",
    "all_metrics = {**train_metrics, **test_metrics}\n",
    "\n",
    "# Prepare metadata\n",
    "metadata = {\n",
    "    \"features\": X_train.columns.tolist(),\n",
    "    \"metrics\": all_metrics,\n",
    "    \"params\": params,\n",
    "    \"data_info\": {\n",
    "        \"n_train\": len(X_train),\n",
    "        \"n_val\": len(X_val),\n",
    "        \"n_test\": len(X_test),\n",
    "        \"symbols\": df[\"symbol\"].unique().tolist(),\n",
    "        \"date_range\": [df[\"timestamp\"].min(), df[\"timestamp\"].max()] if \"timestamp\" in df.columns else None\n",
    "    }\n",
    "}\n",
    "\n",
    "save_model(model, output_path, metadata)\n",
    "print(f\"Model saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "We've trained a baseline XGBoost model to predict stock returns. The model achieves a directional accuracy of around X% on the test set, which is better than random guessing (50%).\n",
    "\n",
    "Next steps:\n",
    "1. Run a backtest to evaluate the model's performance in a simulated trading environment\n",
    "2. Experiment with different feature sets and model hyperparameters\n",
    "3. Implement more sophisticated models (e.g., deep learning models)\n",
    "4. Incorporate alternative data sources (e.g., sentiment analysis from news and social media)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
