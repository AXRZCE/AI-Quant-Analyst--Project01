{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Features Validation\n",
    "\n",
    "This notebook validates the batch features computed by the ETL jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set up plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize Spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"validate_batch_features\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Batch Feature Jobs\n",
    "\n",
    "First, let's run the batch feature jobs to generate the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import the batch feature modules\n",
    "import sys\n",
    "sys.path.append('../src/etl')\n",
    "\n",
    "import batch_features\n",
    "import batch_fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run the batch feature jobs\n",
    "print(\"Running batch_features.py...\")\n",
    "batch_features.main()\n",
    "\n",
    "print(\"\\nRunning batch_fundamentals.py...\")\n",
    "batch_fundamentals.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load technical indicators\n",
    "technical_df = spark.read.format(\"delta\").load(\"../data/features/batch/technical\")\n",
    "\n",
    "# Show schema\n",
    "print(\"Technical Indicators Schema:\")\n",
    "technical_df.printSchema()\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nSample Technical Indicators:\")\n",
    "technical_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert to Pandas for easier analysis\n",
    "technical_pd = technical_df.toPandas()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Technical Indicators Summary Statistics:\")\n",
    "technical_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot technical indicators for a specific symbol\n",
    "symbol = \"AAPL\"  # Change this to any symbol in your data\n",
    "symbol_data = technical_pd[technical_pd['symbol'] == symbol].sort_values('timestamp')\n",
    "\n",
    "if len(symbol_data) > 0:\n",
    "    # Plot price and moving averages\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(symbol_data['timestamp'], symbol_data['close'], label='Close Price')\n",
    "    plt.plot(symbol_data['timestamp'], symbol_data['ma_5'], label='5-period MA')\n",
    "    plt.plot(symbol_data['timestamp'], symbol_data['ma_15'], label='15-period MA')\n",
    "    plt.plot(symbol_data['timestamp'], symbol_data['ma_60'], label='60-period MA')\n",
    "    plt.title(f'{symbol} Price and Moving Averages')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot RSI\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(symbol_data['timestamp'], symbol_data['rsi_14'])\n",
    "    plt.axhline(y=70, color='r', linestyle='-', alpha=0.3)\n",
    "    plt.axhline(y=30, color='g', linestyle='-', alpha=0.3)\n",
    "    plt.title(f'{symbol} RSI (14-period)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('RSI')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot ATR\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(symbol_data['timestamp'], symbol_data['atr_14'])\n",
    "    plt.title(f'{symbol} ATR (14-period)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('ATR')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"No data available for symbol {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validate Fundamental Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load fundamental indicators\n",
    "fundamental_df = spark.read.format(\"delta\").load(\"../data/features/batch/fundamental\")\n",
    "\n",
    "# Show schema\n",
    "print(\"Fundamental Indicators Schema:\")\n",
    "fundamental_df.printSchema()\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nSample Fundamental Indicators:\")\n",
    "fundamental_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert to Pandas for easier analysis\n",
    "fundamental_pd = fundamental_df.toPandas()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Fundamental Indicators Summary Statistics:\")\n",
    "fundamental_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot fundamental indicators\n",
    "if len(fundamental_pd) > 0:\n",
    "    # Plot P/E ratio by symbol\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='symbol', y='price_to_earnings', data=fundamental_pd)\n",
    "    plt.title('Price-to-Earnings Ratio by Symbol')\n",
    "    plt.xlabel('Symbol')\n",
    "    plt.ylabel('P/E Ratio')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot Debt-to-Equity ratio by symbol\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='symbol', y='debt_to_equity', data=fundamental_pd)\n",
    "    plt.title('Debt-to-Equity Ratio by Symbol')\n",
    "    plt.xlabel('Symbol')\n",
    "    plt.ylabel('D/E Ratio')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot sentiment by symbol\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='symbol', y='avg_sentiment', data=fundamental_pd)\n",
    "    plt.title('Average Sentiment by Symbol')\n",
    "    plt.xlabel('Symbol')\n",
    "    plt.ylabel('Sentiment Score')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot mention count by symbol\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='symbol', y='mention_count', data=fundamental_pd)\n",
    "    plt.title('Mention Count by Symbol')\n",
    "    plt.xlabel('Symbol')\n",
    "    plt.ylabel('Mentions')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No fundamental data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Join technical and fundamental data\n",
    "if len(technical_pd) > 0 and len(fundamental_pd) > 0:\n",
    "    # Convert date columns to same format\n",
    "    technical_pd['date'] = pd.to_datetime(technical_pd['date']).dt.date\n",
    "    fundamental_pd['date'] = pd.to_datetime(fundamental_pd['date']).dt.date\n",
    "    \n",
    "    # Group technical data by symbol and date\n",
    "    tech_daily = technical_pd.groupby(['symbol', 'date']).agg({\n",
    "        'close': 'last',\n",
    "        'ma_5': 'last',\n",
    "        'ma_15': 'last',\n",
    "        'ma_60': 'last',\n",
    "        'rsi_14': 'last',\n",
    "        'atr_14': 'last'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Merge with fundamental data\n",
    "    merged_df = pd.merge(tech_daily, fundamental_pd, on=['symbol', 'date'], how='inner')\n",
    "    \n",
    "    if len(merged_df) > 0:\n",
    "        # Select numeric columns for correlation\n",
    "        numeric_cols = merged_df.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        # Compute correlation matrix\n",
    "        corr_matrix = merged_df[numeric_cols].corr()\n",
    "        \n",
    "        # Plot correlation heatmap\n",
    "        plt.figure(figsize=(14, 12))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "        plt.title('Correlation Matrix of Technical and Fundamental Features')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No overlapping data between technical and fundamental indicators\")\n",
    "else:\n",
    "    print(\"Insufficient data for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Indicators\n",
    "- Moving Averages (5, 15, 60-period) provide trend information at different time scales\n",
    "- RSI (14-period) helps identify overbought/oversold conditions\n",
    "- ATR (14-period) measures volatility\n",
    "\n",
    "### Fundamental Indicators\n",
    "- Price-to-Earnings ratio provides valuation context\n",
    "- Debt-to-Equity ratio indicates financial leverage\n",
    "- Sentiment analysis from news provides market perception\n",
    "\n",
    "### Correlation Analysis\n",
    "- Observed relationships between technical and fundamental indicators\n",
    "- Potential for feature selection based on correlation analysis\n",
    "\n",
    "### Next Steps\n",
    "- Integrate these features into the Feast feature store\n",
    "- Use these features for model training and backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
