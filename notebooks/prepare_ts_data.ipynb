{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Time-Series Data\n",
    "\n",
    "This notebook prepares the time-series data for training the Temporal Fusion Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "\n",
    "# Set up plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Technical Features\n",
    "\n",
    "First, let's load the technical features from the batch features directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find all technical feature files\n",
    "technical_files = glob('../data/features/batch/technical/**/*.parquet', recursive=True)\n",
    "print(f\"Found {len(technical_files)} technical feature files\")\n",
    "\n",
    "# If no files found, try loading from raw data\n",
    "if len(technical_files) == 0:\n",
    "    raw_files = glob('../data/raw/ticks/**/*.parquet', recursive=True)\n",
    "    print(f\"Found {len(raw_files)} raw data files\")\n",
    "    \n",
    "    if len(raw_files) > 0:\n",
    "        # Load raw data\n",
    "        dfs = []\n",
    "        for file in raw_files:\n",
    "            try:\n",
    "                df = pd.read_parquet(file)\n",
    "                dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {e}\")\n",
    "        \n",
    "        if dfs:\n",
    "            df = pd.concat(dfs, ignore_index=True)\n",
    "            print(f\"Loaded {len(df)} records from raw data\")\n",
    "        else:\n",
    "            print(\"No data loaded from raw files\")\n",
    "            df = None\n",
    "    else:\n",
    "        print(\"No raw data files found\")\n",
    "        df = None\n",
    "else:\n",
    "    # Load technical features\n",
    "    dfs = []\n",
    "    for file in technical_files:\n",
    "        try:\n",
    "            df = pd.read_parquet(file)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    if dfs:\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "        print(f\"Loaded {len(df)} records from technical features\")\n",
    "    else:\n",
    "        print(\"No data loaded from technical feature files\")\n",
    "        df = None\n",
    "\n",
    "# Try loading from processed data if no data loaded yet\n",
    "if df is None:\n",
    "    processed_file = '../data/processed/training_data.parquet'\n",
    "    if os.path.exists(processed_file):\n",
    "        df = pd.read_parquet(processed_file)\n",
    "        print(f\"Loaded {len(df)} records from processed data\")\n",
    "    else:\n",
    "        print(\"No processed data file found\")\n",
    "        df = None\n",
    "\n",
    "# Check if data was loaded\n",
    "if df is None:\n",
    "    raise ValueError(\"No data could be loaded. Please check the data paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Time-Series Data\n",
    "\n",
    "Now, let's prepare the data for the Temporal Fusion Transformer model by adding a time index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ensure timestamp is datetime\n",
    "if 'timestamp' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort by symbol and timestamp\n",
    "df = df.sort_values(['symbol', 'timestamp'])\n",
    "\n",
    "# Add time_idx (minutes since start)\n",
    "min_timestamp = df['timestamp'].min()\n",
    "df['time_idx'] = ((df['timestamp'] - min_timestamp).dt.total_seconds() / 60).astype(int)\n",
    "\n",
    "print(f\"Time index range: {df['time_idx'].min()} to {df['time_idx'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check the distribution of time_idx\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['time_idx'], bins=50)\n",
    "plt.title('Distribution of time_idx')\n",
    "plt.xlabel('time_idx (minutes since start)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check time_idx by symbol\n",
    "for symbol in df['symbol'].unique():\n",
    "    symbol_df = df[df['symbol'] == symbol]\n",
    "    print(f\"Symbol {symbol}: {len(symbol_df)} records, time_idx from {symbol_df['time_idx'].min()} to {symbol_df['time_idx'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select Features for Time-Series Model\n",
    "\n",
    "Let's select the features we want to use for the time-series model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# List all available features\n",
    "print(\"Available features:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select features for the time-series model\n",
    "required_columns = ['symbol', 'timestamp', 'time_idx', 'close']\n",
    "\n",
    "# Technical indicators\n",
    "technical_columns = [\n",
    "    'open', 'high', 'low', 'volume',\n",
    "    'ma_5', 'ma_15', 'ma_60',\n",
    "    'rsi_14'\n",
    "]\n",
    "\n",
    "# Add volatility features if available\n",
    "volatility_columns = [col for col in df.columns if 'volatility' in col]\n",
    "\n",
    "# Add MACD features if available\n",
    "macd_columns = [col for col in df.columns if 'macd' in col]\n",
    "\n",
    "# Add Bollinger Bands features if available\n",
    "bb_columns = [col for col in df.columns if 'bb_' in col]\n",
    "\n",
    "# Combine all selected features\n",
    "selected_columns = required_columns + technical_columns + volatility_columns + macd_columns + bb_columns\n",
    "\n",
    "# Filter to only include columns that exist in the DataFrame\n",
    "selected_columns = [col for col in selected_columns if col in df.columns]\n",
    "\n",
    "# Create a new DataFrame with selected features\n",
    "ts_df = df[selected_columns].copy()\n",
    "\n",
    "print(f\"Selected {len(selected_columns)} features for the time-series model\")\n",
    "print(f\"Selected features: {selected_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values in selected features\n",
    "missing_values = ts_df.isnull().sum()\n",
    "print(\"Missing values in selected features:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Fill missing values\n",
    "# For time-series data, forward fill is often a good choice\n",
    "ts_df = ts_df.groupby('symbol').apply(lambda x: x.fillna(method='ffill'))\n",
    "\n",
    "# Fill any remaining missing values with backward fill\n",
    "ts_df = ts_df.groupby('symbol').apply(lambda x: x.fillna(method='bfill'))\n",
    "\n",
    "# Check if there are still missing values\n",
    "missing_values = ts_df.isnull().sum()\n",
    "print(\"Missing values after filling:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# If there are still missing values, fill with zeros\n",
    "ts_df = ts_df.fillna(0)\n",
    "\n",
    "# Verify no missing values\n",
    "assert ts_df.isnull().sum().sum() == 0, \"There are still missing values in the data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Prepared Data\n",
    "\n",
    "Now, let's save the prepared data for training the Temporal Fusion Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = '../data/features/batch'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the prepared data\n",
    "output_path = f\"{output_dir}/technical_with_timeidx.parquet\"\n",
    "ts_df.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"Saved prepared time-series data to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Time-Series Data\n",
    "\n",
    "Let's visualize the time-series data to better understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot close price for each symbol\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for symbol in ts_df['symbol'].unique():\n",
    "    symbol_df = ts_df[ts_df['symbol'] == symbol]\n",
    "    plt.plot(symbol_df['timestamp'], symbol_df['close'], label=symbol)\n",
    "\n",
    "plt.title('Close Price by Symbol')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Close Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot technical indicators for a specific symbol\n",
    "symbol = ts_df['symbol'].unique()[0]  # Choose the first symbol\n",
    "symbol_df = ts_df[ts_df['symbol'] == symbol]\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Close price and moving averages\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(symbol_df['timestamp'], symbol_df['close'], label='Close')\n",
    "if 'ma_5' in symbol_df.columns:\n",
    "    plt.plot(symbol_df['timestamp'], symbol_df['ma_5'], label='MA(5)')\n",
    "if 'ma_15' in symbol_df.columns:\n",
    "    plt.plot(symbol_df['timestamp'], symbol_df['ma_15'], label='MA(15)')\n",
    "if 'ma_60' in symbol_df.columns:\n",
    "    plt.plot(symbol_df['timestamp'], symbol_df['ma_60'], label='MA(60)')\n",
    "plt.title(f'{symbol} - Close Price and Moving Averages')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: RSI\n",
    "if 'rsi_14' in symbol_df.columns:\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(symbol_df['timestamp'], symbol_df['rsi_14'])\n",
    "    plt.axhline(y=70, color='r', linestyle='--', alpha=0.5)\n",
    "    plt.axhline(y=30, color='g', linestyle='--', alpha=0.5)\n",
    "    plt.title(f'{symbol} - RSI(14)')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('RSI')\n",
    "    plt.grid(True)\n",
    "\n",
    "# Plot 3: Volume\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.bar(symbol_df['timestamp'], symbol_df['volume'], alpha=0.7)\n",
    "plt.title(f'{symbol} - Volume')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Volume')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "We have successfully prepared the time-series data for training the Temporal Fusion Transformer model. The prepared data includes:\n",
    "\n",
    "1. Time index (minutes since start)\n",
    "2. Technical indicators (moving averages, RSI, etc.)\n",
    "3. Price data (open, high, low, close)\n",
    "4. Volume data\n",
    "\n",
    "The data has been saved to `data/features/batch/technical_with_timeidx.parquet` and is ready for training the TFT model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
